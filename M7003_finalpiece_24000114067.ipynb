{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "from intersect.embedding import get_embedding\n",
    "from intersect.utils import add_you, add_index\n",
    "from intersect.read_pdf import get_text_from_pdf\n",
    "from intersect.semantic_search import similarity_search\n",
    "from intersect.cluster_viz import pca_df, get_chart, add_clusters\n",
    "from intersect.lexical_search import lexical_search\n",
    "from intersect.rerank import rerank_cohere\n",
    "from intersect.tfidf import wordcloud_tfidf, tfidf_words\n",
    "from intersect.ner import wordcloud_ner, ner_count\n",
    "from intersect.permutation import permutation_openai\n",
    "\n",
    "# code repurposed from the web app source code\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "DEFAULT_CV_PATH = \"intersect/data/cvs/g.txt\"\n",
    "table_size = 5\n",
    "n_clusters = 1\n",
    "\n",
    "\n",
    "def get_current_dbs() -> list[str]:\n",
    "    return [\n",
    "        \"ai\",\n",
    "        \"change\",\n",
    "        \"data\",\n",
    "        # \"facilitator\",\n",
    "        \"fun\",\n",
    "        \"law-ai\",\n",
    "        \"law\",\n",
    "        \"leadership\",\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_db_filepath(db_name: str) -> str:\n",
    "    return f\"intersect/data/{db_name}.feather\"\n",
    "\n",
    "\n",
    "def open_and_preprocess_db(_db_name):\n",
    "    original_df = pd.read_feather(get_db_filepath(_db_name))\n",
    "    original_df = original_df.dropna()\n",
    "    original_df = original_df.drop_duplicates(subset=[\"description\"])\n",
    "    original_df[\"i_relevance\"] = original_df.index\n",
    "    original_df[\"id\"] = original_df.index\n",
    "\n",
    "    # add days since posted\n",
    "    original_df[\"timestamp\"] = pd.to_datetime(original_df[\"posted\"], utc=True)\n",
    "    now = datetime.now(timezone.utc)\n",
    "    original_df[\"days_ago\"] = (now - original_df[\"timestamp\"]).dt.days  # type: ignore\n",
    "    return original_df.copy(deep=True)\n",
    "\n",
    "\n",
    "db_name = get_current_dbs()[0]\n",
    "\n",
    "df = open_and_preprocess_db(db_name)\n",
    "\n",
    "\n",
    "location = \"london\"\n",
    "\n",
    "\n",
    "def get_input_text(path) -> str:\n",
    "    with open(path, \"r\") as f:\n",
    "        TEXT = f.read()\n",
    "\n",
    "\n",
    "input_text = get_input_text(DEFAULT_CV_PATH)\n",
    "\n",
    "print(\"Jobs found\", len(original_df))\n",
    "\n",
    "### TFDIF ###\n",
    "\n",
    "wc = tfidf_words(df[\"description\"].tolist())\n",
    "wcdf = pd.DataFrame(list(wc.items()), columns=[\"Word\", \"Frequency\"])\n",
    "wordcloud_tfidf(wc)\n",
    "\n",
    "### RELEVANCE ###\n",
    "\n",
    "view_relevance = df[[\"id\", \"title\", \"company\", \"days_ago\", \"description\", \"url\"]]\n",
    "view_relevance.head(table_size)\n",
    "\n",
    "### SEMANTIC ###\n",
    "\n",
    "input_embedding = get_embedding(OpenAI(), input_text)\n",
    "df = similarity_search(df, input_embedding)  # type: ignore\n",
    "df = add_index(df, \"score_semantic\", \"i_semantic\")\n",
    "\n",
    "view_semantic = df[\n",
    "    [\"id\", \"i_semantic\", \"title\", \"company\", \"days_ago\", \"description\", \"url\"]\n",
    "]\n",
    "\n",
    "view_semantic.head(table_size)\n",
    "\n",
    "### SEMANTIC DELTA ###\n",
    "\n",
    "df[\"delta_semantic\"] = df[\"i_relevance\"] - df[\"i_semantic\"]\n",
    "df_semantic_delta = df.sort_values(\"delta_semantic\", ascending=False)\n",
    "view_semantic_delta = df_semantic_delta[\n",
    "    [\n",
    "        \"id\",\n",
    "        \"i_semantic\",\n",
    "        \"delta_semantic\",\n",
    "        \"title\",\n",
    "        \"company\",\n",
    "        \"days_ago\",\n",
    "        \"description\",\n",
    "        \"url\",\n",
    "    ]\n",
    "]\n",
    "view_semantic_delta.head(table_size)\n",
    "\n",
    "### EMBEDDING PCA ###\n",
    "\n",
    "df_without_you = df.copy()\n",
    "df_you = add_you(df_without_you, input_text, input_embedding)  # type: ignore\n",
    "df_pca = pca_df(df_you, \"embedding\", n_components=2)\n",
    "\n",
    "\n",
    "def generate_chart(_df: pd.DataFrame, n_clusters: int) -> None:\n",
    "    _df = add_clusters(df_pca, n_clusters, n_components=2)\n",
    "    _df.loc[_df[\"title\"] == \"Your text\", \"Cluster\"] = \" You\"\n",
    "    chart = get_chart(_df)\n",
    "    st.altair_chart(chart, use_container_width=True)\n",
    "\n",
    "\n",
    "# generate_chart(df_pca, 1)\n",
    "\n",
    "### LEXICAL ###\n",
    "\n",
    "df = lexical_search(input_text, df)\n",
    "view_lexical = df.sort_values(by=\"score_lexical\", ascending=False)\n",
    "view_lexical = view_lexical[\n",
    "    [\n",
    "        \"id\",\n",
    "        \"i_lexical\",\n",
    "        \"score_lexical\",\n",
    "        \"title\",\n",
    "        \"company\",\n",
    "        \"days_ago\",\n",
    "        \"description\",\n",
    "        \"url\",\n",
    "    ]\n",
    "]\n",
    "view_lexical.head(table_size)\n",
    "\n",
    "### RERANKER ###\n",
    "\n",
    "df = rerank_cohere(input_text, df)\n",
    "df = add_index(df, \"score_reranker\", new_index=\"i_reranker\")\n",
    "view_reranked = df.sort_values(by=\"score_reranker\", ascending=False)\n",
    "view_reranked = view_reranked[\n",
    "    [\n",
    "        \"id\",\n",
    "        \"i_reranker\",\n",
    "        \"score_reranker\",\n",
    "        \"title\",\n",
    "        \"company\",\n",
    "        \"days_ago\",\n",
    "        \"description\",\n",
    "        \"url\",\n",
    "    ]\n",
    "]\n",
    "view_reranked.head(table_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
